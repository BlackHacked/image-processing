{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA编程基础-共享内存与线程同步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as cu\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "import string\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kernel_from_file(fname,kname):\n",
    "    sources = None\n",
    "    kernel = None\n",
    "    with open(fname,encoding='utf-8') as f:\n",
    "        sources = str(f.read())\n",
    "        sm = SourceModule(sources)\n",
    "        kernel = sm.get_function(kname)\n",
    "    return kernel\n",
    "\n",
    "def load_kernel_from_string(sources,kname):\n",
    "    sm = SourceModule(str(sources))\n",
    "    kernel = sm.get_function(kname)\n",
    "    return kernel,sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.静态内存共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = string.Template(\n",
    "\"\"\"\n",
    "#define imin(a,b) (a<b?a:b)\n",
    "\n",
    "const int N = 33 * 1024;\n",
    "const int threadPerBlock = 256;\n",
    "const int blockPerGrid = imin( 32, (N+threadPerBlock-1) / threadPerBlock );\n",
    "\n",
    "    __global__ void dot_static( float *a, float *b, float *c)\n",
    "    {\n",
    "    //共享内存, 每个block都有一份拷贝\n",
    "    __shared__ float cache[threadPerBlock];\n",
    "    // thread的索引\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    // 共享内存的索引,每个block都有cache, 故只用threadIdx.x即可\n",
    "    int cacheIdx = threadIdx.x;\n",
    "\n",
    "    float temp = 0;\n",
    "    while(tid<N)\n",
    "    {\n",
    "        //当前tid的thread负责把tid,和tid间隔threadIdx总量整数倍的向量做乘-加操作.\n",
    "        temp += a[tid] * b[tid];\n",
    "        tid += blockDim.x * gridDim.x;\n",
    "    }\n",
    "    // 完成求和之后,当前thread把和放在对应的cache中\n",
    "    cache[cacheIdx] = temp;\n",
    "    // 在当前block内做同步操作, 等所有thread都完成乘-加运算之后才能做reduction.\n",
    "    __syncthreads();\n",
    "\n",
    "    //reduction, 向量缩减.\n",
    "    //缩减后的结果在cache[0]里.\n",
    "    int i = blockDim.x/2;\n",
    "    while (i!=0)\n",
    "    {\n",
    "        if (cacheIdx<i)\n",
    "        {\n",
    "            cache[cacheIdx] += cache[cacheIdx + i];\n",
    "\n",
    "        }\n",
    "        //同步, 等所有thread都完成了当次缩减了才能做下一次的缩减.\n",
    "        //书上说: 同步不能放在if里面, 否则报错.\n",
    "        //经过试验没有报错, 结果正确.\n",
    "        __syncthreads();\n",
    "        i /= 2;\n",
    "    }\n",
    "    // 一个block输出一个值,即cache[0]. 所以c的长度和block数量相同.\n",
    "    // 限制cacheIdx == 0是为了只做一次赋值操作,节省时间.\n",
    "    if (cacheIdx == 0)\n",
    "    {\n",
    "        c[blockIdx.x] = cache[0];\n",
    "    }\n",
    "    // 没有做剩下的累加操作是因为在CPU上做小批量的累加更加有效.\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    ").substitute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_static,sm = load_kernel_from_string(sources,'dot_static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 33 * 1024\n",
    "threadPerBlock = 256\n",
    "block = (threadPerBlock,1,1)\n",
    "grid = (min(32,int((N+threadPerBlock-1) / threadPerBlock)),1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((N,),dtype=np.float32)\n",
    "b = np.zeros((N,),dtype=np.float32)\n",
    "c = np.zeros_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    a[i] = i\n",
    "    b[i] = i * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_static(cu.In(a),cu.In(b),cu.Out(c),grid=grid,block=block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算剩下的累加求和\n",
    "cc = 0\n",
    "for i in range(grid[0]):\n",
    "    cc += c[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.使用动态内存共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = string.Template(\n",
    "\"\"\"\n",
    "__global__ void reduce0(float *g_idata, float *g_odata) {\n",
    "extern __shared__ float sdata[];\n",
    "// each thread loads one element from global to shared mem\n",
    "unsigned int tid = threadIdx.x;\n",
    "unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "sdata[tid] = g_idata[i];\n",
    "__syncthreads();\n",
    "// do reduction in shared mem\n",
    "for(unsigned int s=1; s < blockDim.x; s *= 2) {\n",
    "   if (tid % (2*s) == 0) {\n",
    "      sdata[tid] += sdata[tid + s];\n",
    "   }\n",
    "__syncthreads();\n",
    "}\n",
    "// write result for this block to global mem\n",
    "if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\"\"\"\n",
    ").substitute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce0,sm = load_kernel_from_string(sources,'reduce0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(400).astype(np.float32)\n",
    "\n",
    "dest = np.zeros_like(a)\n",
    "reduce0(cu.In(a),cu.Out(dest),block=(400,1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
