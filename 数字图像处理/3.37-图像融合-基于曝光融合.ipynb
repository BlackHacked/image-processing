{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于曝光融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "PY3 = sys.version_info > (3,)\n",
    "if PY3:\n",
    "    from builtins import isinstance\n",
    "else:\n",
    "    from __builtin__ import isinstance\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_weights(images, time_decay):\n",
    "    (w_c, w_s, w_e) = (1, 1, 1)\n",
    "\n",
    "    if time_decay is not None:\n",
    "        tau = len(images)\n",
    "        sigma2 = (tau**2)/(np.float32(time_decay)**2)\n",
    "        t = np.array(range(tau-1, -1, -1))\n",
    "        decay = np.exp(-((t)**2)/(2*sigma2))\n",
    "\n",
    "    weights = []\n",
    "    weights_sum = np.zeros(images[0].shape[:2], dtype=np.float32)\n",
    "    i = 0\n",
    "    for image_uint in images:\n",
    "        image = np.float32(image_uint)/255\n",
    "        W = np.ones(image.shape[:2], dtype=np.float32)\n",
    "\n",
    "        # contrast\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        laplacian = cv2.Laplacian(image_gray, cv2.CV_32F)\n",
    "        W_contrast = np.absolute(laplacian) ** w_c + 1\n",
    "        W = np.multiply(W, W_contrast)\n",
    "\n",
    "        # saturation\n",
    "        W_saturation = image.std(axis=2, dtype=np.float32) ** w_s + 1\n",
    "        W = np.multiply(W, W_saturation)\n",
    "\n",
    "        # well-exposedness\n",
    "        sigma2 = 0.4\n",
    "        W_exposedness = np.prod(np.exp(-((image - 0.5)**2)/(2*sigma2)), axis=2, dtype=np.float32) ** w_e + 1\n",
    "        W = np.multiply(W, W_exposedness)\n",
    "\n",
    "        if time_decay is not None:\n",
    "            W *= decay[i]\n",
    "            i += 1\n",
    "\n",
    "        weights_sum += W\n",
    "\n",
    "        weights.append(W)\n",
    "\n",
    "    # normalization\n",
    "    nonzero = weights_sum > 0\n",
    "    for i in range(len(weights)):\n",
    "        weights[i][nonzero] /= weights_sum[nonzero]\n",
    "        weights[i] = np.uint8(weights[i]*255)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def gaussian_kernel(size=5, sigma=0.4):\n",
    "    return cv2.getGaussianKernel(ksize=size, sigma=sigma)\n",
    "\n",
    "\n",
    "def image_reduce(image):\n",
    "    kernel = gaussian_kernel()\n",
    "    out_image = cv2.filter2D(image, cv2.CV_8UC3, kernel)\n",
    "    out_image = cv2.resize(out_image, None, fx=0.5, fy=0.5)\n",
    "    return out_image\n",
    "\n",
    "\n",
    "def image_expand(image):\n",
    "    kernel = gaussian_kernel()\n",
    "    out_image = cv2.resize(image, None, fx=2, fy=2)\n",
    "    out_image = cv2.filter2D(out_image, cv2.CV_8UC3, kernel)\n",
    "    return out_image\n",
    "\n",
    "\n",
    "def gaussian_pyramid(img, depth):\n",
    "    G = img.copy()\n",
    "    gp = [G]\n",
    "    for i in range(depth):\n",
    "        G = image_reduce(G)\n",
    "        gp.append(G)\n",
    "    return gp\n",
    "\n",
    "\n",
    "def laplacian_pyramid(img, depth):\n",
    "    gp = gaussian_pyramid(img, depth+1)\n",
    "    lp = [gp[depth-1]]\n",
    "    for i in range(depth-1, 0, -1):\n",
    "        GE = image_expand(gp[i])\n",
    "        L = cv2.subtract(gp[i-1], GE)\n",
    "        lp = [L] + lp\n",
    "    return lp\n",
    "\n",
    "\n",
    "def pyramid_collapse(pyramid):\n",
    "    depth = len(pyramid)\n",
    "    collapsed = pyramid[depth-1]\n",
    "    for i in range(depth-2, -1, -1):\n",
    "        collapsed = cv2.add(image_expand(collapsed), pyramid[i])\n",
    "    return collapsed\n",
    "\n",
    "\n",
    "def exposure_fusion(images, depth=3, time_decay=None):\n",
    "\n",
    "    if not isinstance(images, list) or len(images) < 2:\n",
    "        print(\"Input has to be a list of at least two images\")\n",
    "        return None\n",
    "\n",
    "    size = images[0].shape\n",
    "    for i in range(len(images)):\n",
    "        if not images[i].shape == size:\n",
    "            print(\"Input images have to be of the same size\")\n",
    "            return None\n",
    "\n",
    "    # compute weights\n",
    "    weights = compute_weights(images, time_decay)\n",
    "\n",
    "    # compute pyramids\n",
    "    lps = []\n",
    "    gps = []\n",
    "    for (image, weight) in zip(images, weights):\n",
    "        lps.append(laplacian_pyramid(image, depth))\n",
    "        gps.append(gaussian_pyramid(weight, depth))\n",
    "\n",
    "    # combine pyramids with weights\n",
    "    LS = []\n",
    "    for l in range(depth):\n",
    "        ls = np.zeros(lps[0][l].shape, dtype=np.uint8)\n",
    "        for k in range(len(images)):\n",
    "            lp = lps[k][l]\n",
    "            gps_float = np.float32(gps[k][l])/255\n",
    "            gp = np.dstack((gps_float, gps_float, gps_float))\n",
    "            lp_gp = cv2.multiply(lp, gp, dtype=cv2.CV_8UC3)\n",
    "            ls = cv2.add(ls, lp_gp)\n",
    "        LS.append(ls)\n",
    "\n",
    "    # collapse pyramid\n",
    "    fusion = pyramid_collapse(LS)\n",
    "    return fusion\n",
    "\n",
    "\n",
    "def align_images(images):\n",
    "\n",
    "    if not isinstance(images, list) or len(images) < 2:\n",
    "        print(\"Input has to be a list of at least two images\")\n",
    "        return None\n",
    "\n",
    "    size = images[0].shape\n",
    "    for i in range(len(images)):\n",
    "        if not images[i].shape == size:\n",
    "            print(\"Input images have to be of the same size\")\n",
    "            return None\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    gray_images = []\n",
    "    for image in images:\n",
    "        gray_images.append(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    model_image = gray_images[0]\n",
    "\n",
    "    # Find size of images\n",
    "    sz = model_image.shape\n",
    "\n",
    "    # Define the motion model\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Specify the number of iterations.\n",
    "    number_of_iterations = 5000\n",
    "\n",
    "    # Specify the threshold of the increment in the correlation coefficient between two iterations\n",
    "    termination_eps = 1e-10\n",
    "\n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "\n",
    "    # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "    aligned_images = [images[0]]\n",
    "    for i in range(1, len(images)):\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(model_image, gray_images[i], warp_matrix, warp_mode, criteria)\n",
    "\n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "            # Use warpPerspective for Homography\n",
    "            aligned_image = cv2.warpPerspective (images[i], warp_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        else:\n",
    "            # Use warpAffine for Translation, Euclidean and Affine\n",
    "            aligned_image = cv2.warpAffine(images[i], warp_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "        aligned_images.append(aligned_image)\n",
    "\n",
    "    return aligned_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exposure_fusion import align_images, exposure_fusion\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('samples/peyrou_mean.jpg')\n",
    "img2 = cv2.imread('samples/peyrou_under.jpg')\n",
    "img3 = cv2.imread('samples/peyrou_over.jpg')\n",
    "\n",
    "images = [img1, img2, img3]\n",
    "\n",
    "aligned_images = align_images(images)\n",
    "\n",
    "fusion = exposure_fusion(aligned_images, depth=4)\n",
    "\n",
    "cv2.imwrite('samples/peyrou_fusion.jpg', fusion)\n",
    "\n",
    "images = []\n",
    "for i in range(1, 5):\n",
    "    img = cv2.imread('samples/time_decay_%d.png' % i)\n",
    "    images.append(img)\n",
    "\n",
    "fusion = exposure_fusion(images, depth=3, time_decay=4)\n",
    "\n",
    "cv2.imwrite('samples/time_decay_fusion.png', fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "[1]. https://github.com/arpesenti/exposure_fusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
